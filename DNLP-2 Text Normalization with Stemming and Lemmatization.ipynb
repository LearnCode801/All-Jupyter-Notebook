{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ba391dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"\"\"It would be unfair to demand that people cease pirating files when those same people aren not paid for their participation in very lucrative network schemes. \n",
    "              Ordinary people are relentlessly spied on, and not compensated for information taken from them. \n",
    "              While I would like to see everyone eventually pay for music and the like, I would not ask for it until there is reciprocity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6262a8c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It would be unfair to demand that people cease pirating files when those same people aren not paid for their participation in very lucrative network schemes. \\n              Ordinary people are relentlessly spied on, and not compensated for information taken from them. \\n              While I would like to see everyone eventually pay for music and the like, I would not ask for it until there is reciprocity.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "638f60d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'would', 'be', 'unfair', 'to', 'demand', 'that', 'people', 'cease', 'pirating', 'files', 'when', 'those', 'same', 'people', 'aren', 'not', 'paid', 'for', 'their', 'participation', 'in', 'very', 'lucrative', 'network', 'schemes', '.', 'Ordinary', 'people', 'are', 'relentlessly', 'spied', 'on', ',', 'and', 'not', 'compensated', 'for', 'information', 'taken', 'from', 'them', '.', 'While', 'I', 'would', 'like', 'to', 'see', 'everyone', 'eventually', 'pay', 'for', 'music', 'and', 'the', 'like', ',', 'I', 'would', 'not', 'ask', 'for', 'it', 'until', 'there', 'is', 'reciprocity', '.']\n"
     ]
    }
   ],
   "source": [
    "# Inorder to start the limitization or the stamming it is required to perform the tokenization\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "sent=word_tokenize(sentence)\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5acb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing the punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e378606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "def remove_punctution(token):\n",
    "    return [word for word in token if word.isalpha()]\n",
    "\n",
    "print(len(sent))\n",
    "sent=remove_punctution(sent)\n",
    "print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46580141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "def remove_punctution(sent):\n",
    "    return_words=[]\n",
    "    for word in sent:\n",
    "        if word in word.isalpha():\n",
    "            return_words.append(word) \n",
    "          \n",
    "       \n",
    "    return return_words\n",
    "\n",
    "\n",
    "print(len(sent))\n",
    "sent=remove_punck(sent)\n",
    "print(len(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e09cbf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "['it', 'would', 'be', 'unfair', 'to', 'demand', 'that', 'people', 'cease', 'pirating', 'files', 'when', 'those', 'same', 'people', 'aren', 'not', 'paid', 'for', 'their', 'participation', 'in', 'very', 'lucrative', 'network', 'schemes', 'ordinary', 'people', 'are', 'relentlessly', 'spied', 'on', 'and', 'not', 'compensated', 'for', 'information', 'taken', 'from', 'them', 'while', 'i', 'would', 'like', 'to', 'see', 'everyone', 'eventually', 'pay', 'for', 'music', 'and', 'the', 'like', 'i', 'would', 'not', 'ask', 'for', 'it', 'until', 'there', 'is', 'reciprocity']\n"
     ]
    }
   ],
   "source": [
    "# Converting all into the lower leter\n",
    "def lower_case(sent):\n",
    "    lower_words=[]\n",
    "    for word in sent:\n",
    "        lower_words.append(word.lower())\n",
    "       \n",
    "    return lower_words\n",
    "\n",
    "sent=lower_case(sent)\n",
    "print(len(sent))\n",
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab2d2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now appling the Stemming using the porterStemer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps=PorterStemmer()\n",
    "\n",
    "stem_sent=[]\n",
    "for word in sent:\n",
    "    stem_sent.append(ps.stem(word))\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0da288c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "['it', 'would', 'be', 'unfair', 'to', 'demand', 'that', 'peopl', 'ceas', 'pirat', 'file', 'when', 'those', 'same', 'peopl', 'aren', 'not', 'paid', 'for', 'their', 'particip', 'in', 'veri', 'lucr', 'network', 'scheme', 'ordinari', 'peopl', 'are', 'relentlessli', 'spi', 'on', 'and', 'not', 'compens', 'for', 'inform', 'taken', 'from', 'them', 'while', 'i', 'would', 'like', 'to', 'see', 'everyon', 'eventu', 'pay', 'for', 'music', 'and', 'the', 'like', 'i', 'would', 'not', 'ask', 'for', 'it', 'until', 'there', 'is', 'reciproc']\n"
     ]
    }
   ],
   "source": [
    "print(len(stem_sent))\n",
    "print(stem_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861a14fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5116e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "['it', 'would', 'be', 'unfair', 'to', 'demand', 'that', 'peopl', 'ceas', 'pirat', 'file', 'when', 'those', 'same', 'peopl', 'aren', 'not', 'paid', 'for', 'their', 'particip', 'in', 'veri', 'lucrat', 'network', 'scheme', 'ordinari', 'peopl', 'are', 'relentless', 'spi', 'on', 'and', 'not', 'compens', 'for', 'inform', 'taken', 'from', 'them', 'while', 'i', 'would', 'like', 'to', 'see', 'everyon', 'eventu', 'pay', 'for', 'music', 'and', 'the', 'like', 'i', 'would', 'not', 'ask', 'for', 'it', 'until', 'there', 'is', 'reciproc']\n"
     ]
    }
   ],
   "source": [
    "# Now appling the Stemming using the SnowballStemmer\n",
    "from nltk.stem import SnowballStemmer\n",
    "ps=SnowballStemmer('english')\n",
    "\n",
    "stem_sent_by_SnowballStemmer=[]\n",
    "for word in sent:\n",
    "    stem_sent_by_SnowballStemmer.append(ps.stem(word))\n",
    "\n",
    "\n",
    "    \n",
    "print(len(stem_sent_by_SnowballStemmer))\n",
    "print(stem_sent_by_SnowballStemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c02b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "334bcffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Muhammad Talha\n",
      "[nltk_data]     Awan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "['it', 'would', 'be', 'unfair', 'to', 'demand', 'that', 'people', 'cease', 'pirating', 'file', 'when', 'those', 'same', 'people', 'aren', 'not', 'paid', 'for', 'their', 'participation', 'in', 'very', 'lucrative', 'network', 'scheme', 'ordinary', 'people', 'are', 'relentlessly', 'spied', 'on', 'and', 'not', 'compensated', 'for', 'information', 'taken', 'from', 'them', 'while', 'i', 'would', 'like', 'to', 'see', 'everyone', 'eventually', 'pay', 'for', 'music', 'and', 'the', 'like', 'i', 'would', 'not', 'ask', 'for', 'it', 'until', 'there', 'is', 'reciprocity']\n"
     ]
    }
   ],
   "source": [
    "# Now Applying the lemmatization\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "\n",
    "lemmatized_sent=[]\n",
    "for word in sent:\n",
    "    lemmatized_sent.append(lemmatizer.lemmatize(word))\n",
    "\n",
    "\n",
    "    \n",
    "print(len(lemmatized_sent))\n",
    "print(lemmatized_sent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b0ea3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f89f41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c85d7ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60481ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
